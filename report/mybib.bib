%Hernández Fusilier, D.; Montes-y-Gómez, M.; Rosso, P.; Guzmán Cabrera, R. Detecting Positive and Negative Deceptive Opinions Using Pu-Learning. Information Processing and Management 2015, 51 (4), 433–443 DOI: 10.1016/j.ipm.2014.11.001.
@article{1,
 title={Detecting Positive and Negative Deceptive Opinions Using Pu-Learning.},
 author={Hernández Fusilier, D.; Montes-y-Gómez, M.; Rosso, P.; Guzmán Cabrera, R},
 journal={Information Processing and Management},
 volume={51 (4)},
 pages={433–443},
 year={2015}
}

% Crawford, M.; Khoshgoftaar, T. M.; Prusa, J. D.; Richter, A. N.; Al Najada, H. Survey of Review Spam Detection Using Machine Learning Techniques. Journal of Big Data 2015, 2 (1), 1–24 DOI: 10.1186/s40537-015-0029-9.
@article{2,
 title={Survey of Review Spam Detection Using Machine Learning Techniques.},
 author={Crawford, M.; Khoshgoftaar, T. M.; Prusa, J. D.; Richter, A. N.; Al Najada, H},
 journal={Journal of Big Data},
 volume={2 (1)},
 pages={1-24},
 year={2015}
}

%Saumya, S.; Singh, J. P. Detection of Spam Reviews: A Sentiment Analysis Approach. Csi Transactions on Ict 2018, 6 (2), 137–148 DOI: 10.1007/s40012-018-0193-0.

@article{3,
 title={Detection of Spam Reviews: A Sentiment Analysis Approach.},
 author={Saumya, S.; Singh, J. P. Detection of Spam Reviews},
 journal={Csi Transactions on Ict},
 volume={6 (2)},
 pages={137–148},
 year={2018}
}


@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{scikitPosthoc,
  title = {Scikit Posthocs},
  howpublished = {\url{https://scikit-posthocs.readthedocs.io/en/latest/}},
  note = {Accessed: 2021-10-14}
}


@misc{scipystats,
  title = {Scipy Stats},
  howpublished = {\url{https://docs.scipy.org/doc/scipy/reference/stats.html}},
  note = {Accessed: 2021-10-14}
}

@article{journals/corr/cs-CL-0205028,
  added-at = {2020-01-10T00:00:00.000+0100},
  author = {Loper, Edward and Bird, Steven},
  biburl = {https://www.bibsonomy.org/bibtex/2eac35636d7e2bb4a0264313ed0791372/dblp},
  ee = {https://arxiv.org/abs/cs/0205028},
  interhash = {1af05e5f1cea0feeea8da5f68707a841},
  intrahash = {eac35636d7e2bb4a0264313ed0791372},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2020-01-11T11:43:05.000+0100},
  title = {NLTK: The Natural Language Toolkit},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr0205.html#cs-CL-0205028},
  volume = {cs.CL/0205028},
  year = 2002
}

@misc{datacamp,
  title = {Stemming and Lemmatization in Python},
  howpublished = {\url{https://www.datacamp.com/community/tutorials/stemming-lemmatization-python}},
  note = {Accessed: 2021-10-14}
}

@article{porter1980algorithm,
  title={An algorithm for suffix stripping},
  author={Porter, Martin F},
  journal={Program},
  year={1980},
  publisher={MCB UP Ltd}
}

@report{Mccallum1998,
   abstract = {Recent approaches to text classification have used two different first-order probabilistic models for classification , both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes-providing on average a 27\% reduction in error over the multi-variate Bernoulli model at any vocabulary size.},
   author = {Andrew Mccallum and Kamal Nigam},
   title = {A Comparison of Event Models for Naive Bayes Text Classification},
   year = {1998},
}

@report{Metsis2006,
   abstract = {Naive Bayes is very popular in commercial and open-source anti-spam e-mail filters. There are, however, several forms of Naive Bayes, something the anti-spam literature does not always acknowledge. We discuss five different versions of Naive Bayes, and compare them on six new, non-encoded datasets, that contain ham messages of particular Enron users and fresh spam messages. The new datasets, which we make publicly available, are more realistic than previous comparable benchmarks, because they maintain the temporal order of the messages in the two categories, and they emulate the varying proportion of spam and ham messages that users receive over time. We adopt an experimental procedure that emulates the incremental training of person-alized spam filters, and we plot roc curves that allow us to compare the different versions of nb over the entire tradeoff between true positives and true negatives.},
   author = {Vangelis Metsis and Georgios Paliouras},
   title = {Spam Filtering with Naive Bayes-Which Naive Bayes? *},
   url = {http://www.iit.demokritos.gr/skel/i-config/},
   year = {2006},
}

@article{morgan1963problems,
  title={Problems in the analysis of survey data, and a proposal},
  author={Morgan, James N and Sonquist, John A},
  journal={Journal of the American statistical association},
  volume={58},
  number={302},
  pages={415--434},
  year={1963},
  publisher={Taylor \& Francis Group}
}

@inproceedings{ho1995random,
  title={Random decision forests},
  author={Ho, Tin Kam},
  booktitle={Proceedings of 3rd international conference on document analysis and recognition},
  volume={1},
  pages={278--282},
  year={1995},
  organization={IEEE}
}

@article{Breiman1996,
   abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy. © 1996 Kluwer Academic Publishers,.},
   author = {Leo Breiman},
   doi = {10.1007/bf00058655},
   issn = {08856125},
   issue = {2},
   journal = {Machine Learning},
   title = {Bagging predictors},
   volume = {24},
   year = {1996},
}

@article{mcnemar1947note,
  title={Note on the sampling error of the difference between correlated proportions or percentages},
  author={McNemar, Quinn},
  journal={Psychometrika},
  volume={12},
  number={2},
  pages={153--157},
  year={1947},
  publisher={Springer}
}

@article{peng2002introduction,
  title={An introduction to logistic regression analysis and reporting},
  author={Peng, Chao-Ying Joanne and Lee, Kuk Lida and Ingersoll, Gary M},
  journal={The journal of educational research},
  volume={96},
  number={1},
  pages={3--14},
  year={2002},
  publisher={Taylor \& Francis}
}

@article{dietterich1998approximate,
  title={Approximate statistical tests for comparing supervised classification learning algorithms},
  author={Dietterich, Thomas G},
  journal={Neural computation},
  volume={10},
  number={7},
  pages={1895--1923},
  year={1998},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{raschkas_2018_mlxtend,
  author       = {Sebastian Raschka},
  title        = {MLxtend: Providing machine learning and data science 
                  utilities and extensions to Python’s  
                  scientific computing stack},
  journal      = {The Journal of Open Source Software},
  volume       = {3},
  number       = {24},
  month        = apr,
  year         = 2018,
  publisher    = {The Open Journal},
  doi          = {10.21105/joss.00638},
  url          = {http://joss.theoj.org/papers/10.21105/joss.00638}
}

@book{breiman2017classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome H and Olshen, Richard A and Stone, Charles J},
  year={2017},
  publisher={Routledge}
}

@article{ott2011finding,
  title={Finding deceptive opinion spam by any stretch of the imagination},
  author={Ott, Myle and Choi, Yejin and Cardie, Claire and Hancock, Jeffrey T},
  journal={arXiv preprint arXiv:1107.4557},
  year={2011}
}

@inproceedings{ott2013negative,
  title={Negative deceptive opinion spam},
  author={Ott, Myle and Cardie, Claire and Hancock, Jeffrey T},
  booktitle={Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: human language technologies},
  pages={497--501},
  year={2013}
}

@book{bird2009natural,
  title={Natural language processing with Python: analyzing text with the natural language toolkit},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={" O'Reilly Media, Inc."}
} 